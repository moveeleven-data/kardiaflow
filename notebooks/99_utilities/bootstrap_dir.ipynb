{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# bootstrap_dir.ipynb\n",
    "# - Create medallion folders (optional) under LAKE_ROOT\n",
    "# - Create dataset folders at the container root (…/encounters, …/claims, …)\n",
    "# - Copy one local sample file per dataset (preserve original filename; skip if exists)\n",
    "\n",
    "# Install kflow only if running on a jobs cluster;\n",
    "# for interactive testing, install via cluster libraries instead.\n",
    "\n",
    "# Optional library bootstrap for ephemeral jobs clusters\n",
    "# %run ./bootstrap_kflow\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from kflow.auth_adls import ensure_adls_oauth\n",
    "from kflow.config import LAKE_ROOT\n",
    "\n",
    "# 1. Authenticate and resolve roots\n",
    "ensure_adls_oauth(validate_path=\"\")\n",
    "\n",
    "lake_root = LAKE_ROOT.rstrip(\"/\")\n",
    "container_root = \"/\".join(lake_root.split(\"/\")[:3])  # drop trailing segment to get container root\n",
    "source_root = f\"{container_root}/source\"\n",
    "dbutils.fs.mkdirs(source_root)\n",
    "\n",
    "print(\"Ensured\",        source_root)\n",
    "print(f\"LAKE_ROOT:      {lake_root}\")\n",
    "print(f\"CONTAINER_ROOT: {container_root}\")\n",
    "\n",
    "# 2. Idempotently create directory structure\n",
    "# Medallion layer folders under lake root\n",
    "for layer in (\"bronze\", \"silver\", \"gold\", \"_schemas\", \"_checkpoints\", \"_quarantine\"):\n",
    "    path = f\"{lake_root}/{layer}\"\n",
    "    dbutils.fs.mkdirs(path)\n",
    "    print(\"Ensured\", path)\n",
    "\n",
    "# Dataset folders at container root\n",
    "datasets = (\"encounters\", \"claims\", \"patients\", \"providers\", \"feedback\")\n",
    "for ds in datasets:\n",
    "    path = f\"{source_root}/{ds}\"\n",
    "    dbutils.fs.mkdirs(path)\n",
    "    print(\"Ensured\", path)\n",
    "\n",
    "\n",
    "# 3. Resolve project root by locating the top-level `data/` directory\n",
    "def find_repo_root_with_data(start: Path = Path.cwd()) -> Path:\n",
    "    for candidate in (start, *start.parents):\n",
    "        if (candidate / \"data\").is_dir():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(f\"Could not find 'data/' under {start} or its parents.\")\n",
    "\n",
    "repo_root = find_repo_root_with_data()\n",
    "print(f\"Detected project root: {repo_root}\")\n",
    "\n",
    "# 4. Local sample definitions\n",
    "samples = {\n",
    "    \"encounters\": \"data/encounters/encounters_part_1.avro\",\n",
    "    \"claims\":     \"data/claims/claims_part_1.parquet\",\n",
    "    \"feedback\":   \"data/feedback/feedback_part_1.jsonl\",\n",
    "    \"patients\":   \"data/patients/patients_part_1.csv\",\n",
    "    \"providers\":  \"data/providers/providers_part_1.tsv\",\n",
    "}\n",
    "\n",
    "# 5. Copy single file per dataset, skip if already present\n",
    "for ds, rel in samples.items():\n",
    "    src_local = (repo_root / rel).resolve()\n",
    "    if not src_local.exists():\n",
    "        print(f\"SKIP {ds}: {src_local} not found.\")\n",
    "        continue\n",
    "\n",
    "    dst_dir = f\"{source_root}/{ds}\"\n",
    "    dst_path = f\"{dst_dir}/{src_local.name}\"\n",
    "\n",
    "    # Ensure destination folder exists (safe/redundant)\n",
    "    dbutils.fs.mkdirs(dst_dir)\n",
    "\n",
    "    # Check for existing file to avoid overwrite\n",
    "    try:\n",
    "        existing = [p.path.split(\"/\")[-1] for p in dbutils.fs.ls(dst_dir)]\n",
    "    except Exception as e:\n",
    "        print(f\"WARNING listing {dst_dir}: {e}\")\n",
    "        existing = []\n",
    "\n",
    "    if src_local.name in existing:\n",
    "        print(f\"SKIP {ds}: {dst_path} already exists.\")\n",
    "        continue\n",
    "\n",
    "    # Copy from local filesystem to ABFS using file: URI\n",
    "    src_uri = f\"file:{src_local.as_posix()}\"\n",
    "    try:\n",
    "        dbutils.fs.cp(src_uri, dst_path)\n",
    "        print(f\"{ds}: copied {src_local.name} -> {dst_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR copying {ds} from {src_uri} to {dst_path}: {e}\")\n",
    "\n",
    "print(\"\\nBootstrap complete – container-root dataset folders populated with sample files.\")"
   ],
   "id": "7752474d7e6e8a98"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
