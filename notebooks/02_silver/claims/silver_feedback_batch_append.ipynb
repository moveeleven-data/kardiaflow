{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67a363bd-2c6c-4a78-b3d1-4545843d8ef9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# silver_feedback_batch_append.ipynb\n",
    "# SOURCE: `kardia_bronze.bronze_feedback` (JSONL with audit metadata)\n",
    "# TARGET: `kardia_silver.silver_feedback` (append-only)\n",
    "# PATTERN: Batch MERGE (insert) on `feedback_id`\n",
    "# TRIGGER: Incremental batch job (no SCD needed; feedback is immutable)\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import MapType, StringType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "from kflow.auth_adls import ensure_adls_oauth\n",
    "from kflow.config import bronze_table, silver_paths\n",
    "\n",
    "# Configure Spark with ADLS OAuth credentials and return base ABFS path\n",
    "abfss_base = ensure_adls_oauth()\n",
    "\n",
    "# Set catalog to Hive Metastore (required when not using Unity Catalog)\n",
    "spark.sql(\"USE CATALOG hive_metastore\")\n",
    "\n",
    "# Load table paths and names for the Feedback dataset\n",
    "S         = silver_paths(\"feedback\")\n",
    "SRC_TABLE = bronze_table(\"feedback\")\n",
    "TGT_TABLE = S.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6d756b0-011c-4939-b16c-13f5bf831d55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Ensure Silver DB and Feedback table exist\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {S.db}\")\n",
    "\n",
    "spark.sql(\n",
    "    f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {TGT_TABLE} (\n",
    "        feedback_id        STRING  NOT NULL,\n",
    "        provider_id        STRING,\n",
    "        timestamp          TIMESTAMP,\n",
    "        visit_id           STRING,\n",
    "        satisfaction_score INT,\n",
    "        comments           STRING,\n",
    "        source             STRING,\n",
    "        tags               ARRAY<STRING>,\n",
    "        metadata           MAP<STRING,STRING>,\n",
    "        _ingest_ts         TIMESTAMP,\n",
    "        _source_file       STRING,\n",
    "        _batch_id          STRING\n",
    "    ) USING DELTA\n",
    "    LOCATION '{S.path}'\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f21887b4-9439-46c6-bb01-81eb494af005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Load Bronze records and prepare deduplicated batch\n",
    "bronze_df = (\n",
    "    spark.table(SRC_TABLE)\n",
    "         .filter(F.col(\"feedback_id\").isNotNull())\n",
    ")\n",
    "\n",
    "# Parse types, select relevant fields, and deduplicate by `feedback_id`\n",
    "base_src = (\n",
    "    bronze_df\n",
    "      .withColumn(\"timestamp\", F.to_timestamp(\"timestamp\"))\n",
    "      .withColumn(\"metadata\", F.from_json(\"metadata_json\", MapType(StringType(), StringType())))\n",
    "      .select(\n",
    "          \"feedback_id\",\n",
    "          \"provider_id\",\n",
    "          \"timestamp\",\n",
    "          \"visit_id\",\n",
    "          \"satisfaction_score\",\n",
    "          \"comments\",\n",
    "          \"source\",\n",
    "          \"tags\",\n",
    "          \"metadata\",\n",
    "          \"_ingest_ts\",\n",
    "          \"_source_file\",\n",
    "          \"_batch_id\"\n",
    "      )\n",
    ")\n",
    "\n",
    "w = Window.partitionBy(\"feedback_id\").orderBy(\n",
    "      F.col(\"timestamp\").desc_nulls_last(),\n",
    "      F.col(\"_ingest_ts\").desc_nulls_last()\n",
    ")\n",
    "\n",
    "silver_src = (\n",
    "    base_src\n",
    "      .withColumn(\"_rn\", F.row_number().over(w))\n",
    "      .filter(F.col(\"_rn\") == 1)\n",
    "      .drop(\"_rn\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34535a61-fe5d-4291-80cb-d190de993263",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. MERGE (insert) new feedback records into Silver table\n",
    "\n",
    "# Refresh so the newly created table is visible to the engine\n",
    "spark.sql(f\"REFRESH TABLE {TGT_TABLE}\")\n",
    "\n",
    "# Path-based DeltaTable to avoid metastore name resolution issues\n",
    "delta = DeltaTable.forPath(spark, S.path)\n",
    "(delta.alias(\"t\")\n",
    "      .merge(silver_src.alias(\"s\"), \"t.feedback_id = s.feedback_id\")\n",
    "      .whenNotMatchedInsertAll()\n",
    "      .execute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d346df86-4858-46a2-9bb1-18ec025a444f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Verify Silver Feedback table row count and preview records.\n",
    "df = spark.table(TGT_TABLE)\n",
    "print(f\"Silver Feedback row count: {df.count():,}\")\n",
    "display(df.orderBy(F.col(\"_ingest_ts\").desc()).limit(5))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_feedback_batch_append",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
